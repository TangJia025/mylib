import streamlit as st

from translation.translation import TranslationAgent
from llmapi.llm_factory import LLMFactory, LLMChatAdapter
from llmapi.util.mylog import logger

class AppUI:
    def __init__(self):
        self.translator = None
        self.llm_chat_adapter = None
        
    def initialize_model(self, model_type, model_name, temperature, top_p):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            llm = LLMFactory.create(model_type, model_name=model_name, temperature=temperature, top_p=top_p)
            self.translator = TranslationAgent(llm)
            self.llm_chat_adapter = LLMChatAdapter(llm)
            logger.info(f"æ¨¡å‹ {model_type}/{model_name} åˆå§‹åŒ–æˆåŠŸ")
            return f"âœ… æ¨¡å‹ {model_type}/{model_name} åˆå§‹åŒ–æˆåŠŸ"
        except Exception as e:
            return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"
    
    def translate_text(self, source_lang, target_lang, source_text, country=""):
        """æ‰§è¡Œç¿»è¯‘"""
        if not self.translator:
            return "âŒ è¯·å…ˆåˆå§‹åŒ–æ¨¡å‹"
        if not source_text.strip():
            return "âŒ è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬"
        
        try:
            return self.translator.translate(source_lang, target_lang, source_text, country, self.llm_chat_adapter)
        except Exception as e:
            logger.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
            return f"âŒ ç¿»è¯‘å¤±è´¥: {str(e)}"
    
    def chat_with_agent(self, message, history):
        """ä¸æ™ºèƒ½ä½“å¯¹è¯"""
        if not self.llm_chat_adapter:
            return history, ""
        
        try:
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            conversation = ""
            for msg in history:
                if msg["role"] == "user":
                    conversation += f"ç”¨æˆ·: {msg['content']}\n"
                elif msg["role"] == "assistant":
                    conversation += f"åŠ©æ‰‹: {msg['content']}\n"
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            conversation += f"ç”¨æˆ·: {message}\nåŠ©æ‰‹: "
            
            # è·å–å›å¤ - LLMChatAdapter.chat è¿”å› (bool, str) å…ƒç»„
            success, response = self.llm_chat_adapter.chat(conversation)
            
            if not success:
                response = f"å¯¹è¯å¤±è´¥: {response}"
            
            # æ›´æ–°å†å²è®°å½•
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": response})
            
            return history, ""
        except Exception as e:
            error_msg = f"å¯¹è¯å¤±è´¥: {str(e)}"
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": error_msg})
            return history, ""
    
    def render_streamlit(self):
        st.set_page_config(page_title="AI åŠ©æ‰‹", layout="wide")
        if "ui" not in st.session_state:
            st.session_state.ui = self
        if "init_status" not in st.session_state:
            st.session_state.init_status = ""
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        st.title("ğŸ¤– AI åŠ©æ‰‹")
        col1, col2 = st.columns([2, 1])
        with col1:
            mt = st.selectbox("æ¨¡å‹ç±»å‹", ["qianfan", "openai", "qwen", "zhipu", "ollama", "siliconflow"], index=0)
            mn = st.text_input("æ¨¡å‹åç§°", value="deepseek-v3")
            t = st.slider("Temperature", 0.0, 2.0, 0.6, 0.1)
            p = st.slider("Top-p", 0.0, 1.0, 0.9, 0.05)
            if st.button("åˆå§‹åŒ–æ¨¡å‹"):
                st.session_state.init_status = self.initialize_model(mt, mn, t, p)
        with col2:
            st.text_area("çŠ¶æ€", value=st.session_state.init_status, height=100)

        tab_chat, tab_trans = st.tabs(["å¯¹è¯", "ç¿»è¯‘"])
        with tab_chat:
            for msg in st.session_state.chat_history:
                with st.chat_message("user" if msg["role"] == "user" else "assistant"):
                    st.markdown(msg["content"])
            user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
            if user_input:
                history = st.session_state.chat_history
                if not self.llm_chat_adapter:
                    history.append({"role": "assistant", "content": "âŒ è¯·å…ˆåˆå§‹åŒ–æ¨¡å‹"})
                else:
                    conversation = ""
                    for m in history:
                        if m["role"] == "user":
                            conversation += f"ç”¨æˆ·: {m['content']}\n"
                        elif m["role"] == "assistant":
                            conversation += f"åŠ©æ‰‹: {m['content']}\n"
                    conversation += f"ç”¨æˆ·: {user_input}\nåŠ©æ‰‹: "
                    ok, resp = self.llm_chat_adapter.chat(conversation)
                    if not ok:
                        resp = f"å¯¹è¯å¤±è´¥: {resp}"
                    history.append({"role": "user", "content": user_input})
                    history.append({"role": "assistant", "content": resp})
                try:
                    st.rerun()
                except Exception:
                    try:
                        st.experimental_rerun()
                    except Exception:
                        pass

        with tab_trans:
            cols = st.columns(3)
            with cols[0]:
                src = st.selectbox("æºè¯­è¨€", ["English", "Chinese", "Japanese", "Korean", "French", "German", "Spanish", "Russian"], index=0)
            with cols[1]:
                tgt = st.selectbox("ç›®æ ‡è¯­è¨€", ["Chinese", "English", "Japanese", "Korean", "French", "German", "Spanish", "Russian"], index=1)
            with cols[2]:
                country = st.text_input("åœ°åŒº (å¯é€‰)", value="")
            source_text = st.text_area("å¾…ç¿»è¯‘æ–‡æœ¬", height=160, placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬...")
            if st.button("å¼€å§‹ç¿»è¯‘"):
                result = self.translate_text(src, tgt, source_text, country)
                st.text_area("ç¿»è¯‘ç»“æœ", value=result, height=160)

if __name__ == "__main__":
    ui = AppUI()
    ui.render_streamlit()